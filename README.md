# BS6204 Medical Image Segmentation Project

<div align="center">

**åŸºäº SegFormer çš„åŒ»å­¦å›¾åƒè¯­ä¹‰åˆ†å‰²é¡¹ç›®**

*Medical Image Semantic Segmentation Using SegFormer Transformer*

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![Lightning](https://img.shields.io/badge/Lightning-2.1+-792ee5.svg)](https://lightning.ai/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

</div>

---

## ğŸ“– é¡¹ç›®ç®€ä»‹ | Project Overview

æœ¬é¡¹ç›®ä½¿ç”¨ NVIDIA çš„ **SegFormer** transformer æ¨¡å‹å¯¹åŒ»å­¦å›¾åƒï¼ˆèƒƒè‚ é“ CT æ‰«æï¼‰è¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼Œå®ç°å¯¹**èƒƒéƒ¨ã€å°è‚ ã€å¤§è‚ **ä¸‰ä¸ªå™¨å®˜çš„è‡ªåŠ¨è¯†åˆ«å’Œåˆ†å‰²ã€‚

This project uses NVIDIA's **SegFormer** transformer model for semantic segmentation of medical images (gastrointestinal CT scans), achieving automatic recognition and segmentation of three organs: **stomach, small intestine, and large intestine**.

### ğŸ¯ ä¸»è¦ç‰¹æ€§ | Key Features

- ğŸ”¥ **å…ˆè¿›æ¶æ„**: åŸºäº Vision Transformer çš„ SegFormer æ¨¡å‹
- âš¡ **é«˜æ€§èƒ½è®­ç»ƒ**: ä½¿ç”¨ PyTorch Lightning æ¡†æ¶ï¼Œæ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ
- ğŸ“Š **å®éªŒè¿½è¸ª**: é›†æˆ Weights & Biases å®æ—¶ç›‘æ§è®­ç»ƒè¿‡ç¨‹
- ğŸ–¼ï¸ **æ•°æ®å¢å¼º**: ä½¿ç”¨ Albumentations è¿›è¡ŒåŒ»å­¦å›¾åƒå¢å¼º
- ğŸ“ˆ **é«˜ç²¾åº¦**: éªŒè¯é›† F1-Score è¾¾åˆ° 0.93-0.95

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ | Quick Start

### ç¯å¢ƒè¦æ±‚ | Requirements

- **GPU**: NVIDIA GPU with 8GB+ VRAM (æ¨è RTX 3060 æˆ–æ›´é«˜)
- **Python**: 3.8+
- **CUDA**: 11.0+

### å®‰è£…ä¾èµ– | Installation

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/PlutoLei/BMDS_group_project.git
cd BMDS_group_project

# å®‰è£… PyTorch (CUDA 11.8)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
pip install transformers==4.35.0 lightning==2.1.0 albumentations==1.3.1
pip install torchmetrics==1.2.0 wandb==0.16.0 opencv-python matplotlib
```

### è¿è¡Œè®­ç»ƒ | Run Training

```bash
# æ‰“å¼€ Jupyter Notebook
jupyter notebook BS6204/Segformer_medical_lightning/Segformer_medical_lightning.ipynb

# æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªå•å…ƒæ ¼
# æ•°æ®é›†ä¼šè‡ªåŠ¨ä¸‹è½½ (~500MB)
```

---

## ğŸ“‚ é¡¹ç›®ç»“æ„ | Project Structure

```
BS6204/
â””â”€â”€ Segformer_medical_lightning/
    â”œâ”€â”€ Segformer_medical_lightning.ipynb  # ä¸»è®­ç»ƒ Notebook
    â””â”€â”€ docs/                               # é¡¹ç›®æ–‡æ¡£
        â”œâ”€â”€ START_TRAINING.md              # å¿«é€Ÿå¼€å§‹æŒ‡å—
        â”œâ”€â”€ Segformer_åŒ»å­¦å›¾åƒåˆ†å‰²_ä½¿ç”¨è¯´æ˜.md  # å®Œæ•´ä½¿ç”¨è¯´æ˜
        â”œâ”€â”€ Segformer_å¿«é€Ÿå¼€å§‹.md            # å¿«é€Ÿå…¥é—¨
        â”œâ”€â”€ Segformer_é…ç½®æ¨èè¡¨.md          # é…ç½®æ¨è
        â”œâ”€â”€ è®­ç»ƒä¼˜åŒ–æ”¹å–„æŠ¥å‘Š_20251014.md     # è®­ç»ƒä¼˜åŒ–æŠ¥å‘Š
        â”œâ”€â”€ é¡¹ç›®ä¼˜åŒ–å®Œæ•´æ€»ç»“_20251014.md     # é¡¹ç›®ä¼˜åŒ–æ€»ç»“
        â””â”€â”€ é¡¹ç›®æ€»ç»“.md                      # é¡¹ç›®æ€»ç»“
```

---

## ğŸ› ï¸ æŠ€æœ¯æ ˆ | Tech Stack

- **æ·±åº¦å­¦ä¹ æ¡†æ¶**: PyTorch 2.0+ & PyTorch Lightning 2.1+
- **æ¨¡å‹**: SegFormer (NVIDIA) - Vision Transformer
- **æ•°æ®å¢å¼º**: Albumentations
- **å®éªŒè¿½è¸ª**: Weights & Biases (WandB)
- **è¯„ä¼°æŒ‡æ ‡**: TorchMetrics (Dice F1-Score)
- **å¯è§†åŒ–**: Matplotlib, OpenCV

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡ | Performance Metrics

| æŒ‡æ ‡ Metric | è®­ç»ƒé›† Train | éªŒè¯é›† Validation |
|-------------|-------------|------------------|
| Loss | 0.25-0.30 | 0.30-0.35 |
| F1-Score (Dice) | 0.95-0.97 | **0.93-0.95** |

### å„ç±»åˆ«æ€§èƒ½ | Per-Class Performance

| ç±»åˆ« Class | F1-Score | éš¾åº¦ Difficulty |
|-----------|----------|----------------|
| èƒŒæ™¯ Background | ~0.98 | ç®€å• Easy |
| èƒƒéƒ¨ Stomach | ~0.92-0.94 | ä¸­ç­‰ Medium |
| å°è‚  Small Intestine | ~0.88-0.92 | å›°éš¾ Hard |
| å¤§è‚  Large Intestine | ~0.90-0.93 | ä¸­ç­‰ Medium |

---

## ğŸ“š æ–‡æ¡£å¯¼èˆª | Documentation

è¯¦ç»†æ–‡æ¡£è¯·æŸ¥çœ‹ `docs/` ç›®å½•ï¼š

1. **[å¿«é€Ÿå¼€å§‹](BS6204/Segformer_medical_lightning/docs/START_TRAINING.md)** - 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹
2. **[å®Œæ•´ä½¿ç”¨è¯´æ˜](BS6204/Segformer_medical_lightning/docs/Segformer_åŒ»å­¦å›¾åƒåˆ†å‰²_ä½¿ç”¨è¯´æ˜.md)** - è¯¦ç»†é…ç½®å’Œä½¿ç”¨æŒ‡å—
3. **[é…ç½®æ¨èè¡¨](BS6204/Segformer_medical_lightning/docs/Segformer_é…ç½®æ¨èè¡¨.md)** - ä¸åŒ GPU çš„é…ç½®å»ºè®®
4. **[è®­ç»ƒä¼˜åŒ–æŠ¥å‘Š](BS6204/Segformer_medical_lightning/docs/è®­ç»ƒä¼˜åŒ–æ”¹å–„æŠ¥å‘Š_20251014.md)** - è®­ç»ƒä¼˜åŒ–ç»†èŠ‚
5. **[é¡¹ç›®æ€»ç»“](BS6204/Segformer_medical_lightning/docs/é¡¹ç›®æ€»ç»“.md)** - é¡¹ç›®å®Œæ•´æ€»ç»“

---

## ğŸ“ æ•°æ®é›† | Dataset

**UW-Madison GI Tract Image Segmentation**

- **æ¥æº**: [Kaggle Competition](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation)
- **å¤§å°**: ~500MB
- **ç±»åˆ«**: 4ç±» (èƒŒæ™¯, èƒƒ, å°è‚ , å¤§è‚ )
- **è®­ç»ƒé›†**: 3,600+ å›¾åƒ
- **éªŒè¯é›†**: 900+ å›¾åƒ
- **å›¾åƒå°ºå¯¸**: 288Ã—288 (é¢„å¤„ç†å)

---

## âš™ï¸ æ”¯æŒçš„æ¨¡å‹ | Supported Models

| æ¨¡å‹ Model | å‚æ•°é‡ Params | æ˜¾å­˜éœ€æ±‚ VRAM | æ¨èç”¨é€” Use Case |
|-----------|--------------|--------------|----------------|
| segformer-b0 | 4M | ~4GB | å¿«é€Ÿå®éªŒ Quick Test |
| segformer-b1 | 14M | ~6GB | å¹³è¡¡æ€§èƒ½ Balanced |
| segformer-b2 | 28M | ~8GB | é«˜ç²¾åº¦ High Accuracy |
| segformer-b3 | 47M | ~10GB | ç”Ÿäº§ç¯å¢ƒ Production |
| **segformer-b4** | **64M** | **~12GB** | **é»˜è®¤ Default** |
| segformer-b5 | 84M | ~16GB | æœ€é«˜ç²¾åº¦ Best |

---

## ğŸ”¬ ä¸»è¦åŠŸèƒ½ | Main Features

### 1. è‡ªåŠ¨æ•°æ®ä¸‹è½½å’Œé¢„å¤„ç†
- è‡ªåŠ¨ä» Kaggle ä¸‹è½½æ•°æ®é›†
- æ™ºèƒ½æ•°æ®å¢å¼ºï¼ˆæ—‹è½¬ã€ç¿»è½¬ã€äº®åº¦è°ƒæ•´ç­‰ï¼‰
- è‡ªåŠ¨åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†

### 2. ç«¯åˆ°ç«¯è®­ç»ƒæµç¨‹
- é…ç½®åŒ–è¶…å‚æ•°ç®¡ç†
- è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- å®æ—¶è®­ç»ƒç›‘æ§å’Œå¯è§†åŒ–

### 3. æ¨¡å‹è¯„ä¼°å’Œæ¨ç†
- å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼ˆDice F1ã€IoUï¼‰
- å¯è§†åŒ–åˆ†å‰²ç»“æœ
- æ”¯æŒæ‰¹é‡æ¨ç†

### 4. å®éªŒè¿½è¸ª
- WandB äº‘ç«¯å®éªŒç®¡ç†
- TensorBoard æœ¬åœ°å¯è§†åŒ–
- è®­ç»ƒæ›²çº¿è‡ªåŠ¨ä¿å­˜

---

## âš ï¸ æ³¨æ„äº‹é¡¹ | Important Notes

1. **åŒ»ç–—ç”¨é€”å£°æ˜**: æœ¬æ¨¡å‹ä»…ç”¨äºæ•™è‚²å’Œç ”ç©¶ç›®çš„ï¼Œä¸åº”ç›´æ¥ç”¨äºä¸´åºŠè¯Šæ–­
2. **æ•°æ®éšç§**: ä½¿ç”¨ç§æœ‰åŒ»å­¦æ•°æ®æ—¶è¯·éµå®ˆç›¸å…³æ³•è§„ï¼ˆHIPAA ç­‰ï¼‰
3. **ç¡¬ä»¶è¦æ±‚**: å»ºè®®ä½¿ç”¨ GPU è®­ç»ƒï¼ŒCPU è®­ç»ƒé€Ÿåº¦ææ…¢ï¼ˆ50-70å°æ—¶ï¼‰
4. **ç‰ˆæœ¬å…¼å®¹**: Python 3.8-3.10ï¼ŒPyTorch 2.0+

---

## ğŸ¤ å‚è€ƒæ–‡çŒ® | References

### è®ºæ–‡ Papers

1. **SegFormer**: [Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203)
2. **Vision Transformer**: [An Image is Worth 16x16 Words](https://arxiv.org/abs/2010.11929)
3. **Dice Loss**: [V-Net: Fully Convolutional Neural Networks](https://arxiv.org/abs/1606.04797)

### èµ„æº Resources

- [PyTorch Lightning æ–‡æ¡£](https://lightning.ai/docs/pytorch/stable/)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers)
- [SegFormer å®˜æ–¹å®ç°](https://github.com/NVlabs/SegFormer)

---

## ğŸ“„ è®¸å¯è¯ | License

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚

**å¼•ç”¨ Citation**:
```bibtex
@article{xie2021segformer,
  title={SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers},
  author={Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M and Luo, Ping},
  journal={NeurIPS},
  year={2021}
}
```

---

## ğŸŒŸ è‡´è°¢ | Acknowledgments

- åŸå§‹æ•°æ®é›†æä¾›: [UW-Madison Carbone Cancer Center](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation)
- SegFormer æ¨¡å‹: [NVIDIA Research](https://github.com/NVlabs/SegFormer)
- å‚è€ƒæ•™ç¨‹: [LearnOpenCV](https://learnopencv.com)

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸€ä¸ª Starï¼**

**If this project helps you, please give it a Star!**

</div>
